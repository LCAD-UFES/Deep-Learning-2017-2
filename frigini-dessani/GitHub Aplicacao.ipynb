{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar CNN - Convolutional Neural Network para identificacão de cones com TensorFlow e Keras \n",
    "\n",
    "## Desde a instalacao do Anaconda ao Treino e Predicao da rede ( VGG16 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando o Anaconda 5.01\n",
    "Acessar o site\n",
    "http://anaconda.com/download\n",
    "\n",
    "Fazer o Download da versao respectiva ao seu SO e também a versao do Python\n",
    "#### Windows\n",
    "Python 3.6\n",
    "https://repo.continuum.io/archive/Anaconda3-5.0.1-Windows-x86_64.exe\n",
    "Python 2.7\n",
    "https://repo.continuum.io/archive/Anaconda2-5.0.1-Windows-x86_64.exe\n",
    "Para instalar é só dar um duplo clique no instalador e seguir \n",
    "\n",
    "#### Linux Ubuntu 16.\n",
    "Python 3.6\n",
    "https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh\n",
    "Python 2.7\n",
    "https://repo.continuum.io/archive/Anaconda2-5.0.1-Linux-x86_64.sh\n",
    "Abrir um terminal, acessar o local onde o arquivo foi baixado e seguir com o seguinte comando\n",
    "bash ~/Downloads/Anaconda3-5.0.1-Linux-x86_64.sh (versao 3.6 do Python)\n",
    "\n",
    "A partir deste momento vou cobrir os passos apenas para o linux como sistema operacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando o Cuda e Cudnn com suporte a GPU\n",
    "Caso queira rodar os treinamentos com recursos de GPU é necessário instalar os pacotes CUDA e Cudnn as versoes destes sao muito importantes para que tudo funcione corretamente como até o momento a ultima versao disponível do tensorflow é a 1.4 vou usar as versões de Cuda e Cudnn que a pagina recomenda como versões suportadas lembrando que a placa de video deve ser compatível com cuda e ter os drivers da nvidia instalados\n",
    "##### Cuda 8.0 GA2\n",
    "Para facilitar a instalacao vou usar o wget\n",
    "abrir um terminal acessar o local onde quer que o arquivo seja baixado\n",
    "    /home/usuario/Downloads\n",
    "    mkdir Cuda\n",
    "    cd Cuda\n",
    "    wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run\n",
    "assim que o download for concluido dar direito de execucao para o arquivo\n",
    "    sudo chmod +x nomeArquivoBaixado\n",
    "    sudo ./nomeArquivoBaixado\n",
    "mesma situacao para o patch desta versao \n",
    "    wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run\n",
    "assim que o download for concluido dar direito de execucao para o arquivo\n",
    "    sudo chmod +x nomeArquivoPatchBaixado\n",
    "    sudo ./nomeArquivoPatchBaixado\n",
    "depois devemos baixar os arquivos do cuda e extrai-los\n",
    "    wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v6/prod/8.0_20170307/Ubuntu16_04_x64/libcudnn6_6.0.20-1+cuda8.0_amd64-deb\n",
    "    sudo dpkg -i nomeArquivoBaixado\n",
    "\n",
    "o proximo passo é a inclusao do caminho destes pacotes no PATH\n",
    "    sudo nano ~/.bashrc\n",
    "inserir no final do arquivo as seguintes linhas\n",
    "    export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\n",
    "    export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64\\\n",
    "                            ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "                            \n",
    "   sudo apt-get install libcupti-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando os pacotes necessários\n",
    "#### Criar um ambiente especifico para este tuto\n",
    "dentro do terminal \n",
    "    conda create -n ufes_lcad python=3.6\n",
    "    source activate ufes_lcad\n",
    "instalar os pacotes basicos que iremos trabalhar\n",
    "    conda install keras\n",
    "    conda install matplotlib\n",
    "    conda install numpy\n",
    "    conda install pandas\n",
    "    conda install scikit-learn\n",
    "    pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando o jupyter notebook\n",
    "dentro do terminal \n",
    "    source activate ufes_lcad\n",
    "    anaconda-navigator ou somente jupyter\n",
    "clicar em new -> python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando a Rede VGG 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importando os pacotes \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo variáveis para ajudar nos parametros de treinamento\n",
    "width, height, batch = 96, 96, 50\n",
    "sgd = SGD(lr=0.01, decay=5e-4, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define que o metodo de montagem do modelo será sequencial camanda por camanda\n",
    "modelo = Sequential()\n",
    "# Construindo a primeira camada\n",
    "# Definimos que esta camada produzirá 64 filtros de saída, seu kernel é de 3 x 3 o stride é de 1 por 1\n",
    "# a entrada será de 224 por 224 colorida, portanto 3 canais e a funcão de ativacao desta camada será a ReLu \n",
    "modelo.add(Conv2D(filters = 64, kernel_size = (3, 3), padding= 'same', strides=(1,1), input_shape = (width, height, 3), activation = 'relu'))\n",
    "# seguindo sequencialmente configuramos a segunda camada, que assume como entrada a saída da camada anterior e por isso \n",
    "# não é preciso declarar este valor, aqui ainda mantemos 4 filtros de saída, kernel de 3 x 3 e stride é de 1 por 1\n",
    "modelo.add(Conv2D(filters = 64, kernel_size = (3, 3), padding='same', strides=(1,1), activation = 'relu'))\n",
    "# seguimos para a primeira camada de max Pooling, está camada tem um pool size kernel de 2 por 2 e um stride também de 2 por 2\n",
    "modelo.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))\n",
    "# com isso concluímos o primeiro bloco da VGG 16, vou considerar o fim de cada bloco sempre após uma camada de pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No segundo bloco da VGG 16 há um aumento no número de saídas das camadas em 2x os outros parametros sao iguais, este\n",
    "# aumento ocorre sempre que houver um pooling e tem fator de multiplicacao 2 limitado a 512\n",
    "modelo.add(Conv2D(filters = 128, kernel_size = (3, 3), padding='same', strides=(1,1), activation = 'relu'))\n",
    "modelo.add(Conv2D(filters = 128, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "# seguimos para a segunda camada de max Pooling, está camada tem um pool size kernel de 2 por 2 e um stride também de 2 por 2\n",
    "modelo.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No terceiro bloco da VGG 16 há um aumento no número de saídas das camadas em 2x e há o acrescimo de mais uma camada \n",
    "# convolucional antes do pooling\n",
    "modelo.add(Conv2D(filters = 256, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 256, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 256, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "# seguimos para a terceira camada de max Pooling, está camada tem um pool size kernel de 2 por 2 e um stride também de 2 por 2\n",
    "modelo.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No quarto bloco da VGG 16 há um aumento no número de saídas das camadas em 2x os outros parametros sao iguais\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu')) \n",
    "# seguimos para a terceira camada de max Pooling, está camada tem um pool size kernel de 2 por 2 e um stride também de 2 por 2\n",
    "modelo.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No quinto bloco da VGG 16 todos parametros sao iguais ao da quarta camada, os valores dos filtros nao sao multiplicados por 2 \n",
    "# porque já atingimos o teto de 512\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu'))\n",
    "modelo.add(Conv2D(filters = 512, kernel_size = (3, 3), padding='same', strides=(1,1), activation= 'relu')) \n",
    "# seguimos para a quarta camada de max Pooling, está camada tem um pool size kernel de 2 por 2 e um stride também de 2 por 2\n",
    "modelo.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neste momento preparamos a saída para o formato que a entrada da primeira camada FullyConnected precisa\n",
    "modelo.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serão 3 camadas FC \n",
    "# a primeira tem uma entrada de tamanho de 4096 e funcao de ativacao relu\n",
    "modelo.add(Dense(units = 4096, activation = 'relu'))\n",
    "# logo após a primeira camada FC é feito um dropout com taxa de 50%\n",
    "modelo.add(Dropout(0.5))\n",
    "# a segunda camada FC tem a mesma configuracao da primeira\n",
    "modelo.add(Dense(units = 4096, activation = 'relu'))\n",
    "# logo após a segunda camada FC é feito mais um dropout com taxa de 50%\n",
    "modelo.add(Dropout(0.5))\n",
    "# a terceira camada na rede original VGG16 tem entrada de tamanho 1000, pois a mesma classifica 1000 classes\n",
    "# devido a nossa necessidade de classificar apenas 3 classes o meu numero de entrada para a terceira camada será de 3\n",
    "# a funcao de ativacao da terceira camada a softmax\n",
    "modelo.add(Dense(units = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# antes de compilar o modelo defino que o mesmo irá rodar em multiplas GPUs que no meu caso sao 3\n",
    "#modelo = multi_gpu_model(modelo, gpus=3)\n",
    "# Seguindo agora para a compilacao do modelo temos como funcao de otimizacao o SGD e a funcao de perda Crossentropy\n",
    "modelo.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8591 images belonging to 3 classes.\n",
      "Found 2200 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# antes de iniciar o treino da rede precisamos definir onde estão as fotos que serao usadas para treino\n",
    "# e onde estao as fotos que serao usadas para teste\n",
    "# para aumentar o numero de amostras de fotos utilzamos o recurso do keras que aumenta/diminui a foto, inverte, gira e etc\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# definimos entao onde esta o diretorio contendo o dataset separado em pastas com a seguinte hierarquia\n",
    "# dentro da pasta dataset temos mais duas pastas com nome treino e teste\n",
    "# dentro de cada uma das pastas de treino e teste temos a quantidade de pastas equivalente as classes no meu caso 3\n",
    "# ou seja tenho 3 pastas dentro da pasta treino e mais 3 pastas dentro da pasta teste\n",
    "# elas devem ter o mesmo nome e conter a classe que será treinada\n",
    "\n",
    "# aqui definimos também o formato que será a entrada da primeira camada de rede, \n",
    "# o padrao de entrada para a VGG16 224 x 224 x 3 \n",
    "# o batch padrao da VGG16 é de 256\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', target_size = (width, height), batch_size = batch, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set', target_size = (width, height), batch_size = batch, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 134,272,835\n",
      "Trainable params: 134,272,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# antes de iniciar o treino podemos exibir como está montada a rede\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8591/8591 [==============================] - 1742s 203ms/step - loss: 0.7207 - acc: 0.5983 - val_loss: 0.5243 - val_acc: 0.7432\n",
      "Epoch 2/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.4056 - acc: 0.8233 - val_loss: 0.2860 - val_acc: 0.8845\n",
      "Epoch 3/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.1495 - acc: 0.9432 - val_loss: 0.3093 - val_acc: 0.9159\n",
      "Epoch 4/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.0463 - acc: 0.9838 - val_loss: 0.2839 - val_acc: 0.9268\n",
      "Epoch 5/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.3837 - val_acc: 0.9305\n",
      "Epoch 6/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.3595 - val_acc: 0.9291\n",
      "Epoch 7/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.3848 - val_acc: 0.9382\n",
      "Epoch 8/15\n",
      "8591/8591 [==============================] - 1739s 202ms/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.4255 - val_acc: 0.9368\n",
      "Epoch 9/15\n",
      "8591/8591 [==============================] - 1743s 203ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.4529 - val_acc: 0.9332\n",
      "Epoch 10/15\n",
      "8591/8591 [==============================] - 1741s 203ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.4512 - val_acc: 0.9355\n",
      "Epoch 11/15\n",
      "8591/8591 [==============================] - 1741s 203ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.4113 - val_acc: 0.9391\n",
      "Epoch 12/15\n",
      "8591/8591 [==============================] - 1742s 203ms/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.4474 - val_acc: 0.9391\n",
      "Epoch 13/15\n",
      "8591/8591 [==============================] - 1744s 203ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.4186 - val_acc: 0.9291\n",
      "Epoch 14/15\n",
      "8591/8591 [==============================] - 1745s 203ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.4317 - val_acc: 0.9382\n",
      "Epoch 15/15\n",
      "8591/8591 [==============================] - 1744s 203ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.3911 - val_acc: 0.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84d572e1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# podemos agora iniciar o treinamento da nossa rede\n",
    "# aqui ainda definimos o numero de passos por treino e validacao e tambem a quantidade de epochs\n",
    "modelo.fit_generator(training_set, steps_per_epoch = 8591, epochs = 15, validation_data = test_set, validation_steps = 2200,  use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'cone': 1, 'dogs': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size = (96, 96))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = modelo.predict(test_image)\n",
    "print(result)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "## Save model pesos\n",
    "modelo.save('VGG16.h5')\n",
    "print(\"Model saved\")    \n",
    "## Save model estrutura\n",
    "modelo_json = modelo.to_json()\n",
    "with open(\"VGG16Estrutura.json\", \"w\") as json_file:\n",
    "    json_file.write(modelo_json)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
